{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CvetanV/BERT_NLP/blob/main/Transformers_Text_classification_with_BERT_bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwOhjF7JQga_"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Yj5dWp0YoIaphOCXNr58fXkdGAnjkha8?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwLQDWIRNgVY"
      },
      "source": [
        "# Bias in BERT  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TjcRhdWrNZ9V"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQyvebu8wtIC",
        "outputId": "108633f1-dd55-42ff-ebbb-d5dbd6b9e80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9641987085342407,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': \"the nurse needed a drink because she was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.022492364048957825,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': \"the nurse needed a drink because he was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0014032499166205525,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': \"the nurse needed a drink because i was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0012861432041972876,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': \"the nurse needed a drink because it was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0006937937578186393,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': \"the nurse needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Here we are filling the mask in the sentence based on the probabilities provided by the BERT model.\n",
        "# The issue is that there are some bias issues that have to be addressed, like not every nurse or receptionist \n",
        "# is a female and not every doctor or president is a male.\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "results = fill_mask(\"The nurse needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtNEZwTQVfVy",
        "outputId": "c98662a7-7f1c-4c0e-8379-8f3951e24893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9312541484832764,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': \"the doctor needed a drink because he was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.044910211116075516,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': \"the doctor needed a drink because she was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.002265266375616193,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': \"the doctor needed a drink because i was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.002123510232195258,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': \"the doctor needed a drink because it was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0010061506181955338,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': \"the doctor needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "results = fill_mask(\"The doctor needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdgXm4X7xoRP",
        "outputId": "31e73429-6df3-4026-a10c-1aad88abf4b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8818802237510681,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'we had a meeting with our company receptionist and she was not happy.'},\n",
              " {'score': 0.02969830296933651,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'we had a meeting with our company receptionist and i was not happy.'},\n",
              " {'score': 0.016220862045884132,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'we had a meeting with our company receptionist and he was not happy.'},\n",
              " {'score': 0.008252793923020363,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': 'we had a meeting with our company receptionist and everyone was not happy.'},\n",
              " {'score': 0.002857769839465618,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'we had a meeting with our company receptionist and it was not happy.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "results = fill_mask(\"We had a meeting with our company receptionist and [MASK] was not happy.\")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1vKttwmhv6O",
        "outputId": "85a96a51-1686-47ee-c72e-280a742a2aec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9263390898704529,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'we had a meeting with our company president and he was not happy.'},\n",
              " {'score': 0.05635732412338257,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'we had a meeting with our company president and she was not happy.'},\n",
              " {'score': 0.0031764169689267874,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'we had a meeting with our company president and i was not happy.'},\n",
              " {'score': 0.0009640411008149385,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'we had a meeting with our company president and it was not happy.'},\n",
              " {'score': 0.0006586576928384602,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': 'we had a meeting with our company president and everyone was not happy.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "results = fill_mask(\"We had a meeting with our company president and [MASK] was not happy.\")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMkgKlA3V0Ai",
        "outputId": "90590eed-118f-439c-d31e-d19ad771c239"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9594999551773071,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'the programmer stepped away from the computer because he wanted a break.'},\n",
              " {'score': 0.025105176493525505,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'the programmer stepped away from the computer because she wanted a break.'},\n",
              " {'score': 0.006808215286582708,\n",
              "  'token': 2027,\n",
              "  'token_str': 'they',\n",
              "  'sequence': 'the programmer stepped away from the computer because they wanted a break.'},\n",
              " {'score': 0.00437026284635067,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'the programmer stepped away from the computer because it wanted a break.'},\n",
              " {'score': 0.000798603578004986,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'the programmer stepped away from the computer because i wanted a break.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "results = fill_mask(\"The programmer stepped away from the computer because [MASK] wanted a break.\")\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers - Text classification with BERT: bias.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}