{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SXrKAeEundU"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/16bjnXxKZzgAc8njhqqVAuVn7EqVr_hcY?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmx-6YifWLLQ"
      },
      "source": [
        "**NLP use cases**\n",
        "- Classifying whole sentences\n",
        "- Classifying each word in a sentence (Named Entity Recognition)\n",
        "- Answering a question given a context\n",
        "- Text summarization\n",
        "- Fill in the blanks\n",
        "- Translating from one language to another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cd-h9TkLuc_6"
      },
      "outputs": [],
      "source": [
        "# Install transformers framework\n",
        "%%capture\n",
        "!pip install transformers[sentencepiece] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn6UpqR3uhLQ"
      },
      "source": [
        "### Note: You need to have installed also tensorflow in anaconda using:\n",
        "1. conda create -n tf tensorflow\n",
        "\n",
        "2. conda activate tf\n",
        "\n",
        "or\n",
        "\n",
        "1. conda create -n tf-gpu tensorflow-gpu\n",
        "\n",
        "2. conda activate tf-gpu\n",
        "\n",
        "or \n",
        "\n",
        "1. pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "39XhY1Y-uzMK"
      },
      "outputs": [],
      "source": [
        "# Imports the `pipeline` function from the `transformers` library and the `TextWrapper` class from the `textwrap` module.\n",
        "# `pipeline` is a function that makes it easy to use pre-trained transformer models for a variety of natural language \n",
        "# processing (NLP) tasks, such as text classification, question answering, and text generation. It abstracts away many \n",
        "# of the implementation details and provides a simple interface for input and output.\n",
        "# `TextWrapper` is a class that can be used to format text by wrapping long lines of text and breaking them into \n",
        "# multiple lines that fit within a specified width. In this code, it creates an instance of the `TextWrapper` class \n",
        "# with a `width` of 80 and two options: `break_long_words` and `break_on_hyphens`, which are set to `False`. \n",
        "# The `width` parameter specifies the maximum line length for the text, and the other two parameters control how words \n",
        "# are wrapped. `break_long_words` specifies whether to break long words or not, and `break_on_hyphens` specifies whether \n",
        "# to break lines at hyphens or not.\n",
        "\n",
        "from transformers import pipeline\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=80, break_long_words=False, break_on_hyphens=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93QbwOgisBCK"
      },
      "source": [
        "## Classifying whole sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcWBiNRru7ta",
        "outputId": "bdf90cf4-346a-47b5-df5f-f396a88bcc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:\n",
            "The flights were on time both in Sydney and the connecting flight in Singapore.\n",
            "The organisation to cope with the COVID 19 restrictions while in transit was\n",
            "well planned and directions easy to follow, the plane was comfortable with a\n",
            "reasonable selection of in flight entertainment. Crew were pleasant and helpful.\n",
            "\n",
            "This sentence is classified with a POSITIVE sentiment\n"
          ]
        }
      ],
      "source": [
        "# This code is using the Hugging Face Transformers library to classify the sentiment of a given sentence. \n",
        "# First, it imports the `pipeline` module from the Transformers library, which is a high-level module that \n",
        "# allows you to perform various natural language processing tasks with pre-trained models. \n",
        "# Then, it imports the `textwrap` module from the standard library to help with formatting the output. \n",
        "# It creates a `TextWrapper` object that specifies a maximum line width of 80 characters and turns off \n",
        "# breaking long words and hyphenated words. It then defines a `sentence` variable that contains a sample sentence.\n",
        "# Next, it initializes a text classification pipeline using the `pipeline` function from the Transformers library.\n",
        "# The pipeline is initialized with the `'text-classification'` task and the `distilbert-base-uncased-finetuned-sst-2-english` \n",
        "# pre-trained model. This model has been fine-tuned on the Stanford Sentiment Treebank dataset, which is a dataset of movie \n",
        "# reviews labeled with their sentiment (positive or negative).\n",
        "# The `classifier` object is then used to classify the sentiment of the `sentence`. \n",
        "# The resulting object `c` is a list of dictionaries, with each dictionary representing a possible label and its \n",
        "# corresponding score.\n",
        "# Finally, it prints the original `sentence` variable formatted with the `TextWrapper` object, and the predicted sentiment \n",
        "# label and its corresponding score.\n",
        "\n",
        "sentence = 'The flights were on time both in Sydney and the connecting flight in Singapore. The organisation to cope with the COVID 19 restrictions while in transit was well planned and directions easy to follow, the plane was comfortable with a reasonable selection of in flight entertainment. Crew were pleasant and helpful.'\n",
        "classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
        "c = classifier(sentence)\n",
        "print('\\nSentence:')\n",
        "print(wrapper.fill(sentence))\n",
        "print(f\"\\nThis sentence is classified with a {c[0]['label']} sentiment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvvab0H3sfgh"
      },
      "source": [
        "## Classifying each word in a sentence (Named Entity Recognition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF6vLguV6lkz",
        "outputId": "92b0a3ff-1476-4518-b7c5-c64fd573783b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:\n",
            "Singapore Airlines was the first airline to fly the A380. Chew Choon Seng was\n",
            "Singapore Airline's CEO at the time. Singapore Airlines flies to New York daily.\n",
            "\n",
            "\n",
            "Singapore Airlines -> ORG\n",
            "A380 -> MISC\n",
            "Chew Choon Seng -> PER\n",
            "Singapore Airline -> ORG\n",
            "Singapore Airlines -> ORG\n",
            "New York -> LOC\n"
          ]
        }
      ],
      "source": [
        "# This code uses the Hugging Face Transformers library to perform named entity recognition (NER) on a given sentence \n",
        "# using the pre-trained model \"dbmdz/bert-large-cased-finetuned-conll03-english\". \n",
        "# After importing the required packages and defining the input sentence, the `pipeline` function is called to \n",
        "# initialize a text classification pipeline with the pre-trained model specified. The `token-classification` task \n",
        "# is used here as it involves identifying and labeling individual tokens in the input text. The `grouped_entities` \n",
        "# parameter is set to `True` to group consecutive tokens with the same entity label.\n",
        "# The `ners` variable stores the results of the NER task performed on the input sentence. \n",
        "# Finally, the script prints the input sentence using the `textwrap` module to wrap lines at a maximum width of 80 characters.\n",
        "# It then loops through each entity identified by the NER model and prints the word and its corresponding entity group.\n",
        "\n",
        "sentence = \"Singapore Airlines was the first airline to fly the A380. Chew Choon Seng was Singapore Airline's CEO at the time. Singapore Airlines flies to New York daily.\"\n",
        "ner = pipeline('token-classification', model='dbmdz/bert-large-cased-finetuned-conll03-english', grouped_entities=True)\n",
        "ners = ner(sentence)\n",
        "print('\\nSentence:')\n",
        "print(wrapper.fill(sentence))\n",
        "print('\\n')\n",
        "for n in ners:\n",
        "  print(f\"{n['word']} -> {n['entity_group']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGGSYtXLtF_S"
      },
      "source": [
        "## Answering a question given a context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrEtUj8BtF_S",
        "outputId": "387bbbdf-d2e1-475d-97ed-2d3e9533b19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            " Singapore Airlines was founded in 1947 and was originally known as Malayan\n",
            "Airways. It is the national airline of Singapore and is based at Singapore\n",
            "Changi Airport.  From this hub, the airline flies to more than 60 destinations,\n",
            "with flights to Seoul, Tokyo and Melbourne among the most popular of its routes.\n",
            "It is particularly strong in Southeast Asian and Australian destinations (the\n",
            "so-called Kangaroo Route), but also flies to 6 different continents, covering 35\n",
            "countries. There are more than 100 planes in the Singapore Airlines fleet, most\n",
            "of which are Airbus aircraft plus a smaller amount of Boeings. The company is\n",
            "known for frequently updating the aircraft in its fleet.\n",
            "\n",
            "Question:\n",
            "How many aircrafts does Singapore Airlines have?\n"
          ]
        }
      ],
      "source": [
        "context = '''\n",
        "Singapore Airlines was founded in 1947 and was originally known as Malayan Airways. It is the national airline of Singapore and is based at Singapore Changi Airport. \n",
        "From this hub, the airline flies to more than 60 destinations, with flights to Seoul, Tokyo and Melbourne among the most popular of its routes. \n",
        "It is particularly strong in Southeast Asian and Australian destinations (the so-called Kangaroo Route), but also flies to 6 different continents, covering 35 countries.\n",
        "There are more than 100 planes in the Singapore Airlines fleet, most of which are Airbus aircraft plus a smaller amount of Boeings.\n",
        "The company is known for frequently updating the aircraft in its fleet.'''\n",
        "\n",
        "\n",
        "question = 'How many aircrafts does Singapore Airlines have?'\n",
        "\n",
        "print('Text:')\n",
        "print(wrapper.fill(context))\n",
        "print('\\nQuestion:')\n",
        "print(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "DPUX75hiDdlU",
        "outputId": "6f0fd4e8-38c6-4ca1-e6d8-8b49901bf926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question:\n",
            "How many aircrafts does Singapore Airlines have?\n",
            "\n",
            "Answer:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'more than 100'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# The code is using the Transformers library to create a question-answering pipeline using the \n",
        "# 'distilbert-base-cased-distilled-squad' model. Once the pipeline is created, it uses the context and question \n",
        "# variables to generate an answer.\n",
        "# The 'context' variable refers to the text where the answer to the question can be found, while the 'question' \n",
        "# variable refers to the actual question being asked.\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "qa = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')\n",
        "\n",
        "print('\\nQuestion:')\n",
        "print(question + '\\n')\n",
        "print('Answer:')\n",
        "a = qa(context=context, question=question)\n",
        "a['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os4TWQ9XAQgk"
      },
      "source": [
        "## Text summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVbliCgwtF_T",
        "outputId": "6a4200f9-3341-41f3-de95-d7510e4c82ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original text:\n",
            "\n",
            " Extremely unusual time to fly as we needed an exemption to fly out of Australia\n",
            "from the government. We obtained one as working in Tokyo for the year as\n",
            "teachers. The check in procedure does take a lot longer as more paperwork and\n",
            "phone calls are needed to check if you are allowed to travel. The staff were\n",
            "excellent in explaining the procedure as they are working with very few numbers.\n",
            "The flight had 40 people only, so lots of room and yes we had 3 seats each. The\n",
            "service of meals and beverages was done very quickly and efficiently. Changi\n",
            "airport was like a ghost town with most shops closed and all passengers are\n",
            "walked/transported to a transit zone until your next flight is ready. You are\n",
            "then walked in single file or transported to your next flight, so very strange\n",
            "as at times their seemed be more workers in PPE gear than passengers. The steps\n",
            "we went through at Narita were extensive, downloading apps, fill in paperwork\n",
            "and giving a saliva sample to test for covid 19.  It took about 2 hours to get\n",
            "through the steps and we only sat down for maybe 10 minutes at the last stop to\n",
            "get back your covid results.  The people involved were fantastic and we were\n",
            "lucky that we were numbers two and three in the initial first line up, but still\n",
            "over 2 hours it took so be aware. We knew we were quick as the people picking us\n",
            "up told us we were first out.\n",
            "\n",
            "Summarized text:\n",
            " The flight had 40 people only, so lots of room and yes we had 3 seats each .\n",
            "The check in procedure does take a lot longer as more paperwork and phone calls\n",
            "are needed to check if you are allowed to travel . The staff were excellent in\n",
            "explaining the procedure as they are working with very few numbers .\n"
          ]
        }
      ],
      "source": [
        "review = '''\n",
        "Extremely unusual time to fly as we needed an exemption to fly out of Australia from the government. We obtained one as working in Tokyo for the year as teachers.\n",
        "The check in procedure does take a lot longer as more paperwork and phone calls are needed to check if you are allowed to travel. The staff were excellent in explaining the procedure as they are working with very few numbers.\n",
        "The flight had 40 people only, so lots of room and yes we had 3 seats each. The service of meals and beverages was done very quickly and efficiently.\n",
        "Changi airport was like a ghost town with most shops closed and all passengers are walked/transported to a transit zone until your next flight is ready. You are then walked in single file or transported to your next flight, so very strange as at times their seemed be more workers in PPE gear than passengers.\n",
        "The steps we went through at Narita were extensive, downloading apps, fill in paperwork and giving a saliva sample to test for covid 19. \n",
        "It took about 2 hours to get through the steps and we only sat down for maybe 10 minutes at the last stop to get back your covid results. \n",
        "The people involved were fantastic and we were lucky that we were numbers two and three in the initial first line up, but still over 2 hours it took so be aware. We knew we were quick as the people picking us up told us we were first out.'''\n",
        "\n",
        "print('\\nOriginal text:\\n')\n",
        "print(wrapper.fill(review))\n",
        "summarize = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')\n",
        "summarized_text = summarize(review)[0]['summary_text']\n",
        "print('\\nSummarized text:')\n",
        "print(wrapper.fill(summarized_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6WQFMF0v1Ts"
      },
      "source": [
        "## Fill in the blanks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YgMzrVGxrGq",
        "outputId": "bff00e58-9dcc-4a17-c6f6-35ffbed66853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is the national anthem of Singapore\n",
            "It is the national capital of Singapore\n",
            "It is the national pride of Singapore\n",
            "It is the national treasure of Singapore\n",
            "It is the national motto of Singapore\n"
          ]
        }
      ],
      "source": [
        "# The output of the code will be five possible completion of the sentence \"It is the national <mask> of Singapore\" \n",
        "# using the `fill-mask` pipeline from Hugging Face's transformers library. The pipeline predicts the masked word \n",
        "# given the context provided. \n",
        "# Each of the five possible completions will be printed on a separate line, and each completion will have replaced \n",
        "# the `<mask>` with a predicted word based on the model's knowledge.\n",
        "\n",
        "sentence = 'It is the national <mask> of Singapore'\n",
        "mask = pipeline('fill-mask', model='distilroberta-base')\n",
        "masks = mask(sentence)\n",
        "for m in masks:\n",
        "  print(m['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj63RtEuNl0Z",
        "outputId": "8de66ea2-bb31-4e5f-9dce-b8c5b0757860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singapore Airlines is the national airline of Singapore\n",
            "Singapore Airlines is the national carrier of Singapore\n",
            "Singapore Airlines is the national airport of Singapore\n",
            "Singapore Airlines is the national airlines of Singapore\n",
            "Singapore Airlines is the national capital of Singapore\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Singapore Airlines is the national <mask> of Singapore'\n",
        "mask = pipeline('fill-mask', model='distilroberta-base')\n",
        "masks = mask(sentence)\n",
        "for m in masks:\n",
        "  print(m['sequence'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7xGy6XkBUSt"
      },
      "source": [
        "## Translation (English to German)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuylAnUBCQX7",
        "outputId": "d88b52cf-db16-42e5-e27e-80f0f404c837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "English:\n",
            "Singapore Airlines is my favourite airline\n",
            "\n",
            "German:\n",
            "Singapore Airlines ist meine Lieblingsfluggesellschaft\n"
          ]
        }
      ],
      "source": [
        "# The code above uses the Hugging Face `pipeline` module to perform English to German translation using the `t5-base` model. \n",
        "# The `pipeline` function takes two arguments: the task to be performed (`translation_en_to_de`) and \n",
        "# the name of the model (`t5-base`). \n",
        "# Then, the `translator` function is called with the English sentence as input. \n",
        "# The output is a list with a single dictionary item, which contains the translated sentence under the \n",
        "# key `'translation_text'`. \n",
        "# Finally, the original and translated sentences are printed to the console using the `print` function.\n",
        "\n",
        "english = '''Singapore Airlines is my favourite airline'''\n",
        "\n",
        "translator = pipeline('translation_en_to_de', model='t5-base')\n",
        "german = translator(english)\n",
        "print('\\nEnglish:')\n",
        "print(english)\n",
        "print('\\nGerman:')\n",
        "print(german[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Iknl9Q2QuhLu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP tasks with Transformers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}